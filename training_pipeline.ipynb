{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a02ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    ")\n",
    "\n",
    "bucket_name = 'kursai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce0e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model_LinearRegression.pkl\n",
      "halfmarathon_wroclaw_2023__final.csv\n",
      "halfmarathon_wroclaw_2024__final.csv\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    print(obj['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d34cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/envs/kursAI/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/envs/kursAI/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/kursAI/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/envs/kursAI/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/miniconda3/envs/kursAI/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandera as pa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import joblib\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd77614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane połączone: (21957, 27)\n"
     ]
    }
   ],
   "source": [
    "#Wczytanie i połączenie danych\n",
    "# Wczytujemy oba pliki CSV i łączymy je w jeden DataFrame.\n",
    "\n",
    "df_2023 = pd.read_csv(f\"s3://{bucket_name}/halfmarathon_wroclaw_2023__final.csv\", sep=';')\n",
    "df_2024 = pd.read_csv(f\"s3://{bucket_name}/halfmarathon_wroclaw_2024__final.csv\", sep=';')\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "print('Dane połączone:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6807a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane po czyszczeniu: (7009, 27)\n"
     ]
    }
   ],
   "source": [
    "# Walidacja i czyszczenie danych (pandera)\n",
    "# Tworzymy schemat walidacji i czyścimy dane zgodnie z nim.\n",
    "schema = pa.infer_schema(df)\n",
    "df = schema.validate(df)\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "print('Dane po czyszczeniu:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77ce2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybrane cechy: ['Miejsce', 'Płeć Miejsce', '5 km Miejsce Open', '5 km Tempo', '10 km Miejsce Open', '10 km Tempo', '15 km Miejsce Open', '15 km Tempo', '20 km Miejsce Open', '20 km Tempo']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wybieramy cechy na podstawie metryk statystycznych. Zakładamy, że przewidujemy kolumnę 'Czas'\n",
    "target = 'Czas'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Konwersja czasu z formatu HH:MM:SS do liczby sekund\n",
    "def time_to_seconds(t):\n",
    "\tif isinstance(t, str) and ':' in t:\n",
    "\t\tparts = t.split(':')\n",
    "\t\tif len(parts) == 3:\n",
    "\t\t\th, m, s = map(int, parts)\n",
    "\t\t\treturn h * 3600 + m * 60 + s\n",
    "\t\telif len(parts) == 2:\n",
    "\t\t\tm, s = map(int, parts)\n",
    "\t\t\treturn m * 60 + s\n",
    "\treturn np.nan\n",
    "\n",
    "y_numeric = y.apply(time_to_seconds)\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "selector = SelectKBest(score_func=f_regression, k=min(10, X.shape[1]))\n",
    "X_selected = selector.fit_transform(X, y_numeric)\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "X = X[selected_features]\n",
    "print('Wybrane cechy:', list(selected_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18bf009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9af7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porównanie modeli:\n",
      "LinearRegression: {'MAE': 22.321375437539345, 'MSE': 848.3973835513754, 'R2': 0.9994540210313967}\n",
      "RandomForest: {'MAE': 17.881141226818833, 'MSE': 1629.6846419400854, 'R2': 0.99895123021687}\n",
      "\n",
      "Najlepszy model (wg R2, MAE, MSE): LinearRegression\n"
     ]
    }
   ],
   "source": [
    "# Trening i porównanie modeli scikit-learn\n",
    "# Trenujemy kilka modeli i porównujemy ich skuteczność.\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42)\n",
    "    }\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Convert y_train and y_test to seconds using the same logic as y_numeric\n",
    "    y_train_numeric = y_train.apply(time_to_seconds)\n",
    "    y_test_numeric = y_test.apply(time_to_seconds)\n",
    "    model.fit(X_train, y_train_numeric)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test_numeric, y_pred),\n",
    "        'MSE': mean_squared_error(y_test_numeric, y_pred),\n",
    "        'R2': r2_score(y_test_numeric, y_pred)\n",
    "    }\n",
    "print('Porównanie modeli:')\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: {metrics}\")\n",
    "\n",
    "# Wybór najlepszego modelu\n",
    "sorted_models = sorted(\n",
    "    results.items(),\n",
    "    key=lambda x: (-x[1]['R2'], x[1]['MAE'], x[1]['MSE'])\n",
    ")\n",
    "best_model_name = sorted_models[0][0]\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nNajlepszy model (wg R2, MAE, MSE): {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e6ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane cechy: ['gender', 'age', 'pace_5k']\n",
      "Porównanie modeli:\n",
      "LinearRegression: {'MAE': 279.6483647412662, 'MSE': 142174.92719967576, 'R2': 0.9085045267480649}\n",
      "RandomForest: {'MAE': 309.4213135345198, 'MSE': 178743.20461004108, 'R2': 0.8849713207632263}\n",
      "\n",
      "Najlepszy model (wg R2, MAE, MSE): LinearRegression\n",
      "Pipeline zapisany do pliku: best_model_pipeline.joblib\n",
      "Pipeline wysłany do Digital Ocean Spaces: kursai/best_model_pipeline.joblib\n",
      "Przykładowe wartości y (sekundy): Series([], Name: Czas_numeric, dtype: int64)\n",
      "Przykładowe wartości pace_5k: Series([], Name: pace_5k, dtype: float64)\n",
      "Statystyki czasu: count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: Czas_numeric, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ...po wczytaniu i czyszczeniu danych...\n",
    "\n",
    "# Przygotuj tylko te cechy, które możesz wyciągnąć z tekstu\n",
    "def time_to_seconds(t):\n",
    "    if isinstance(t, str) and ':' in t:\n",
    "        parts = t.split(':')\n",
    "        if len(parts) == 3:\n",
    "            h, m, s = map(int, parts)\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:\n",
    "            m, s = map(int, parts)\n",
    "            return m * 60 + s\n",
    "    return np.nan\n",
    "\n",
    "df['Czas_numeric'] = df['Czas'].apply(time_to_seconds)\n",
    "\n",
    "# Zakładamy, że masz kolumny: 'Płeć', 'Wiek', 'Tempo_5km' (dostosuj nazwy do swoich danych!)\n",
    "df['gender'] = df['Płeć'].map({'M': 0, 'K': 1})  # dostosuj mapowanie do wartości w Twojej kolumnie 'Płeć'\n",
    "current_year = pd.Timestamp.now().year\n",
    "df['age'] = current_year - df['Rocznik']\n",
    "df['pace_5k'] = df['5 km Tempo']  # już w sekundach na km w Twoich danych\n",
    "\n",
    "X = df[['gender', 'age', 'pace_5k']]\n",
    "y = df['Czas_numeric']\n",
    "\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "print('Używane cechy:', X.columns.tolist())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "print('Porównanie modeli:')\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: {metrics}\")\n",
    "\n",
    "# Wybierz najlepszy model\n",
    "sorted_models = sorted(\n",
    "    results.items(),\n",
    "    key=lambda x: (-x[1]['R2'], x[1]['MAE'], x[1]['MSE'])\n",
    ")\n",
    "best_model_name = sorted_models[0][0]\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nNajlepszy model (wg R2, MAE, MSE): {best_model_name}\")\n",
    "\n",
    "# Pipeline (tu nie potrzebujesz selektora cech)\n",
    "pipeline = Pipeline([\n",
    "    ('model', best_model)\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "import joblib\n",
    "model_path = \"best_model_pipeline.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(f\"Pipeline zapisany do pliku: {model_path}\")\n",
    "\n",
    "# Upload do Digital Ocean Spaces (jak wcześniej)\n",
    "import boto3\n",
    "session = boto3.session.Session()\n",
    "client = session.client('s3')\n",
    "bucket = 'kursai'\n",
    "client.upload_file(model_path, bucket, model_path)\n",
    "print(f\"Pipeline wysłany do Digital Ocean Spaces: {bucket}/{model_path}\")\n",
    "print(\"Przykładowe wartości y (sekundy):\", y.head())\n",
    "print(\"Przykładowe wartości pace_5k:\", X['pace_5k'].head())\n",
    "print(\"Statystyki czasu:\", y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92f428e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba rekordów po czyszczeniu: 7009\n",
      "Przykładowe wartości y (sekundy): 1    3983\n",
      "3    4216\n",
      "4    4227\n",
      "6    4278\n",
      "7    4302\n",
      "Name: Czas_numeric, dtype: int64\n",
      "Przykładowe wartości pace_5k (min/km): 1    2.960000\n",
      "3    3.236667\n",
      "4    3.240000\n",
      "6    3.123333\n",
      "7    3.300000\n",
      "Name: pace_5k, dtype: float64\n",
      "Statystyki czasu: count     7009.000000\n",
      "mean      7197.278642\n",
      "std       1220.741752\n",
      "min       3864.000000\n",
      "25%       6337.000000\n",
      "50%       7081.000000\n",
      "75%       7909.000000\n",
      "max      12512.000000\n",
      "Name: Czas_numeric, dtype: float64\n",
      "Porównanie modeli:\n",
      "LinearRegression: {'MAE': 279.6483647412662, 'MSE': 142174.92719967576, 'R2': 0.9085045267480649}\n",
      "RandomForest: {'MAE': 309.4213135345198, 'MSE': 178743.20461004108, 'R2': 0.8849713207632263}\n",
      "\n",
      "Najlepszy model (wg R2, MAE, MSE): LinearRegression\n",
      "Pipeline zapisany do pliku: best_model_pipeline.joblib\n",
      "Pipeline wysłany do Digital Ocean Spaces: kursai/best_model_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# ...po wczytaniu i czyszczeniu danych...\n",
    "\n",
    "def time_to_seconds(t):\n",
    "    if isinstance(t, str) and ':' in t:\n",
    "        parts = t.split(':')\n",
    "        if len(parts) == 3:\n",
    "            h, m, s = map(int, parts)\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:\n",
    "            m, s = map(int, parts)\n",
    "            return m * 60 + s\n",
    "    return np.nan\n",
    "\n",
    "df['Czas_numeric'] = df['Czas'].apply(time_to_seconds)\n",
    "\n",
    "# Przygotuj cechy: gender, age, pace_5k (w minutach na km!)\n",
    "df['gender'] = df['Płeć'].map({'M': 0, 'K': 1})  # dostosuj mapowanie do swoich danych\n",
    "current_year = pd.Timestamp.now().year\n",
    "df['age'] = current_year - df['Rocznik']\n",
    "\n",
    "# Użyj bezpośrednio kolumny '5 km Tempo', która już jest w minutach na km\n",
    "df['pace_5k'] = df['5 km Tempo']\n",
    "\n",
    "X = df[['gender', 'age', 'pace_5k']]\n",
    "y = df['Czas_numeric']\n",
    "\n",
    "# Usuń tylko wiersze z brakami w tych cechach\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data = data.dropna(subset=['gender', 'age', 'pace_5k', 'Czas_numeric'])\n",
    "X = data[['gender', 'age', 'pace_5k']]\n",
    "y = data['Czas_numeric']\n",
    "\n",
    "print('Liczba rekordów po czyszczeniu:', len(X))\n",
    "print('Przykładowe wartości y (sekundy):', y.head())\n",
    "print('Przykładowe wartości pace_5k (min/km):', X['pace_5k'].head())\n",
    "print('Statystyki czasu:', y.describe())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred)\n",
    "    }\n",
    "print('Porównanie modeli:')\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: {metrics}\")\n",
    "\n",
    "sorted_models = sorted(\n",
    "    results.items(),\n",
    "    key=lambda x: (-x[1]['R2'], x[1]['MAE'], x[1]['MSE'])\n",
    ")\n",
    "best_model_name = sorted_models[0][0]\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nNajlepszy model (wg R2, MAE, MSE): {best_model_name}\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', best_model)\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "import joblib\n",
    "model_path = \"best_model_pipeline.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(f\"Pipeline zapisany do pliku: {model_path}\")\n",
    "\n",
    "import boto3\n",
    "session = boto3.session.Session()\n",
    "client = session.client('s3')\n",
    "bucket = 'kursai'\n",
    "client.upload_file(model_path, bucket, model_path)\n",
    "print(f\"Pipeline wysłany do Digital Ocean Spaces: {bucket}/{model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83fd9d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline zapisany do pliku: best_model_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Stwórz pipeline z wybranymi cechami i najlepszym modelem\n",
    "pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_regression, k=len(selected_features))),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "# Dopasuj pipeline do całych danych treningowych (przekształć y na sekundy)\n",
    "pipeline.fit(X_train, y_train.apply(time_to_seconds))\n",
    "\n",
    "# Zapisz pipeline do pliku\n",
    "model_path = \"best_model_pipeline.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(f\"Pipeline zapisany do pliku: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d33efcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline wysłany do Digital Ocean Spaces: kursai/best_model_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "session = boto3.session.Session()\n",
    "client = session.client(\n",
    "    's3',\n",
    ")\n",
    "\n",
    "bucket = 'kursai'  # zmień na swój bucket jeśli inny\n",
    "client.upload_file(model_path, bucket, model_path)\n",
    "print(f\"Pipeline wysłany do Digital Ocean Spaces: {bucket}/{model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kursAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
